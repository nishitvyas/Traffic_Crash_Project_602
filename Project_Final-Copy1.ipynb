{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b10762a",
   "metadata": {},
   "source": [
    "# Library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2303cbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4160aee1",
   "metadata": {},
   "source": [
    "# Model Pipelines & Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c485ba16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_splits(X,y, test_size=0.15, random_state=101, stratify=None):\n",
    "    X = X\n",
    "    y = y\n",
    "    random_state = random_state\n",
    "    test_size = test_size\n",
    "    stratify = stratify\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size= test_size, random_state=random_state, stratify=stratify)\n",
    "    return(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d637fb5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a3a06e8",
   "metadata": {},
   "source": [
    "# Read Data and Basic Get to know the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "947e0ba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>jurisdiction</th>\n",
       "      <th>number_of_lanes</th>\n",
       "      <th>fatal_count</th>\n",
       "      <th>young</th>\n",
       "      <th>deer</th>\n",
       "      <th>crash_id</th>\n",
       "      <th>lighting</th>\n",
       "      <th>occupants</th>\n",
       "      <th>b_level_count</th>\n",
       "      <th>...</th>\n",
       "      <th>highway_classification</th>\n",
       "      <th>crash_type</th>\n",
       "      <th>train</th>\n",
       "      <th>weather</th>\n",
       "      <th>property_damage</th>\n",
       "      <th>lane_departure</th>\n",
       "      <th>primary_road</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>drug</th>\n",
       "      <th>elderly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7929715</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HENDRIE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7931144</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>E STATE FAIR</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7854992</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>FOREST AVE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7940235</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>W FOREST AVE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7932532</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>109C</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   OBJECTID  jurisdiction  number_of_lanes  fatal_count  young  deer  \\\n",
       "0         1           4.0                2            0      0     0   \n",
       "1         2           5.0                0            0      0     0   \n",
       "2         3           4.0                2            0      0     0   \n",
       "3         4           4.0                2            0      0     0   \n",
       "4         5           1.0                1            0      0     0   \n",
       "\n",
       "   crash_id  lighting  occupants  b_level_count  ...  highway_classification  \\\n",
       "0   7929715         1          2              0  ...                       9   \n",
       "1   7931144         1          3              0  ...                       9   \n",
       "2   7854992         1          0              0  ...                       9   \n",
       "3   7940235         1          3              0  ...                       9   \n",
       "4   7932532         1          1              0  ...                       3   \n",
       "\n",
       "   crash_type  train  weather  property_damage  lane_departure  primary_road  \\\n",
       "0           4      0        2                1               0       HENDRIE   \n",
       "1           4      0        1                1               0  E STATE FAIR   \n",
       "2           5      0        2                1               0    FOREST AVE   \n",
       "3           8      0        1                1               0  W FOREST AVE   \n",
       "4           1      0        5                1               1          109C   \n",
       "\n",
       "   alcohol  drug  elderly  \n",
       "0        0     0        0  \n",
       "1        0     0        0  \n",
       "2        0     0        0  \n",
       "3        0     0        0  \n",
       "4        0     0        0  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crashesDf = pd.read_csv('https://raw.githubusercontent.com/nvyas1-git/Traffic_Crash_Project_602/main/data/Traffic_Crashes.csv')\n",
    "crashesDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "08435fb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crashesDf['jurisdiction'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190928d2",
   "metadata": {},
   "source": [
    "## Cleaning the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1573744a",
   "metadata": {},
   "outputs": [],
   "source": [
    "crashesDfClean = crashesDf.drop(columns=['OBJECTID', 'crash_id'], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81cfb038",
   "metadata": {},
   "outputs": [],
   "source": [
    "crashesDfNAClean = crashesDfClean.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6028bb6c",
   "metadata": {},
   "source": [
    "__Differentiating the columns based on their values such as boolean columns and columns having more than two values__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71159969",
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_value_cats = ['young', 'deer', 'pedestrian', 'dis_ctrl_i', 'school_bus', 'hit_and_run', 'bicycle', 'motorcycle',\n",
    "                 'red_light_running', 'train', 'property_damage']\n",
    "\n",
    "more_value_cats = ['lane_departure', 'weather', 'crash_type', 'highway_classification','weekday', 'most_severe_injury', 'a_level_count',\n",
    "                   'b_level_count', 'c_level_count', 'number_of_units', 'road_condition', 'lighting', 'fatal_count', 'number_of_lanes',\n",
    "                   'jurisdiction']\n",
    "\n",
    "more_than_20_value_cats = ['hour','speed_limit', 'occupants']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b8d772",
   "metadata": {},
   "source": [
    "## Labelling the target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08c0535e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Non-Consumed Youth               116928\n",
       "Non-Consumed Elder                15181\n",
       "Alcohol Consumed Youth             2597\n",
       "Drug Consumed Youth                 298\n",
       "Alcohol & Drug Consumed Youth       289\n",
       "Alcohol Consumed Elder              167\n",
       "Drug Consumed Elder                  44\n",
       "Alcohol & Drug Consumed Elder        40\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Class Fragmentation as per target and then combining them into One Dataframe\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    dfADE = crashesDfNAClean[(crashesDfNAClean['alcohol']==1)&(crashesDfNAClean['drug']==1)&(crashesDfNAClean['elderly']==1)]\n",
    "    dfADE['target'] = 'Alcohol & Drug Consumed Elder'\n",
    "    dfAE = crashesDfNAClean[(crashesDfNAClean['alcohol']==1)&(crashesDfNAClean['drug']==0)&(crashesDfNAClean['elderly']==1)]\n",
    "    dfAE['target'] = 'Alcohol Consumed Elder'\n",
    "    dfDE = crashesDfNAClean[(crashesDfNAClean['alcohol']==0)&(crashesDfNAClean['drug']==1)&(crashesDfNAClean['elderly']==1)]\n",
    "    dfDE['target'] = 'Drug Consumed Elder'\n",
    "    dfE = crashesDfNAClean[(crashesDfNAClean['alcohol']==0)&(crashesDfNAClean['drug']==0)&(crashesDfNAClean['elderly']==1)]\n",
    "    dfE['target'] = 'Non-Consumed Elder'\n",
    "    dfADY = crashesDfNAClean[(crashesDfNAClean['alcohol']==1)&(crashesDfNAClean['drug']==1)&(crashesDfNAClean['elderly']==0)]\n",
    "    dfADY['target'] = 'Alcohol & Drug Consumed Youth'\n",
    "    dfAY = crashesDfNAClean[(crashesDfNAClean['alcohol']==1)&(crashesDfNAClean['drug']==0)&(crashesDfNAClean['elderly']==0)]\n",
    "    dfAY['target'] = 'Alcohol Consumed Youth'\n",
    "    dfDY = crashesDfNAClean[(crashesDfNAClean['alcohol']==0)&(crashesDfNAClean['drug']==1)&(crashesDfNAClean['elderly']==0)]\n",
    "    dfDY['target'] = 'Drug Consumed Youth'\n",
    "    dfY = crashesDfNAClean[(crashesDfNAClean['alcohol']==0)&(crashesDfNAClean['drug']==0)&(crashesDfNAClean['elderly']==0)]\n",
    "    dfY['target'] = 'Non-Consumed Youth'\n",
    "\n",
    "    crashesDfNAClean = pd.concat([dfADE,dfAE,dfDE,dfE,dfADY,dfAY, dfDY, dfY], axis=0)\n",
    "crashesDfNAClean['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866da0ff",
   "metadata": {},
   "source": [
    "__There is a huge class imbalance in the data, we will train the Machine Learning model with the imbalance and then will try to use upsampling methods to balance the classes__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9647caa",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faff7e27",
   "metadata": {},
   "source": [
    "## Column Selection for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea05d234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['number_of_lanes', 'fatal_count', 'lighting', 'occupants',\n",
       "       'b_level_count', 'pedestrian', 'road_condition', 'number_of_units',\n",
       "       'speed_limit', 'hour', 'hit_and_run', 'bicycle', 'motorcycle',\n",
       "       'a_level_count', 'c_level_count', 'most_severe_injury',\n",
       "       'red_light_running', 'weekday', 'highway_classification', 'crash_type',\n",
       "       'weather', 'property_damage', 'lane_departure', 'target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping the features that we won't use in the model\n",
    "modelDF=crashesDfNAClean.drop(columns=['jurisdiction','deer','dis_ctrl_i','intersecting_road','primary_road','young',\n",
    "                                       'datetime','alcohol','drug','elderly','school_bus','train'])\n",
    "modelDF.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cf3e1f",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8a20abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment of features to X and y\n",
    "X = modelDF.drop(columns='target')\n",
    "y = modelDF['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6cda4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split\n",
    "X_train, X_test, y_train, y_test = create_splits(X=X,y=y, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5622e8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0eafbc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322685ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49918237",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483b018e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a24401da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "def mlflow_runLogR(model_params, exp_name='TrafficCrash', run_Name='run1'):\n",
    "    pipeline = Pipeline(\n",
    "        [\n",
    "            (\"clf\", LogisticRegression())\n",
    "        ]\n",
    "    )\n",
    "    mlflow.set_experiment(exp_name)\n",
    "    with mlflow.start_run(run_name=run_Name):\n",
    "        best_params = model_params\n",
    "        pipeline.set_params(**best_params)\n",
    "        pipeline.fit(X_train,y_train)\n",
    "        prediction = pipeline.predict(X_test)\n",
    "        Accuracy_score = round(metrics.accuracy_score(y_test, prediction)*100,2)\n",
    "        \n",
    "        print('Accuracy_score', Accuracy_score)\n",
    "        print(best_params['clf__penalty'])\n",
    "        mlflow.log_param(\"penalty\", best_params['clf__penalty'])\n",
    "        mlflow.log_param(\"max_iter\", best_params['clf__max_iter'])\n",
    "        mlflow.log_param(\"solver\", best_params['clf__solver'])\n",
    "        mlflow.log_metric(\"Accuracy_score\", Accuracy_score)\n",
    "        mlflow.log_metric(\"Recall\", round(metrics.recall_score(y_test,prediction, average='weighted')*100,2))\n",
    "        mlflow.log_metric(\"F1-score\", round(metrics.f1_score(y_test,prediction,average='weighted')*100,2))\n",
    "\n",
    "\n",
    "        mlflow.sklearn.log_model('clf', \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9db395b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nishit Vyas\\anaconda3\\envs\\MLEnv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_score 86.25\n",
      "l2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nishit Vyas\\anaconda3\\envs\\MLEnv\\lib\\site-packages\\_distutils_hack\\__init__.py:30: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'clf__penalty': 'l2',\n",
    "             'clf__solver': 'lbfgs',\n",
    "             'clf__max_iter': 1000}\n",
    "mlflow_runLogR(model_params=param_grid,exp_name='TrafficCrash', run_Name='run1' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "575726d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!mlflow ui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27933bf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Non-Consumed Youth               116928\n",
       "Non-Consumed Elder                15181\n",
       "Alcohol Consumed Youth             2597\n",
       "Drug Consumed Youth                 298\n",
       "Alcohol & Drug Consumed Youth       289\n",
       "Alcohol Consumed Elder              167\n",
       "Drug Consumed Elder                  44\n",
       "Alcohol & Drug Consumed Elder        40\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counts of classes with respect to their record occurrence in the data\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8be30635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Alcohol & Drug Consumed Elder    116928\n",
       "Alcohol Consumed Elder           116928\n",
       "Drug Consumed Elder              116928\n",
       "Non-Consumed Elder               116928\n",
       "Alcohol & Drug Consumed Youth    116928\n",
       "Alcohol Consumed Youth           116928\n",
       "Drug Consumed Youth              116928\n",
       "Non-Consumed Youth               116928\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SMOTE Upsampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE()\n",
    "X_sm, y_sm = smote.fit_resample(X,y)\n",
    "\n",
    "y_sm.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0fc74bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Splits\n",
    "X_train, X_test, y_train, y_test = create_splits(X_sm,y_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8fc7b2f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nishit Vyas\\anaconda3\\envs\\MLEnv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_score 37.96\n",
      "l2\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'clf__penalty': 'l2',\n",
    "             'clf__solver': 'lbfgs',\n",
    "             'clf__max_iter': 1000}\n",
    "mlflow_runLogR(model_params=param_grid,exp_name='TrafficCrash', run_Name='run3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "01b1e641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!mlflow ui"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b405c08",
   "metadata": {},
   "source": [
    "## Class Reduction\n",
    "\n",
    "__First we have fragmented the classes as per the three column values (alcohol, elderly and drug) and then merged them into one.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb0b5be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drug:  (342, 36)\n",
      "Alcohol:  (2764, 36)\n",
      "Alcohol Drug:  (329, 36)\n",
      "Unconsumed:  (132109, 36)\n",
      "Summation of categorized records 135544\n",
      "CrashesDF records:  135544\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Clean      132109\n",
       "Alcohol      2764\n",
       "Drug          671\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Class Fragmentation as per target and then combining them into One Dataframe\n",
    "drug_consumptionDf = crashesDfNAClean[(crashesDfNAClean['alcohol']==0)&(crashesDfNAClean['drug']==1)]\n",
    "print('Drug: ',drug_consumptionDf.shape)\n",
    "\n",
    "alcohol_consumptionDf = crashesDfNAClean[(crashesDfNAClean['alcohol']==1)&(crashesDfNAClean['drug']==0)]\n",
    "print('Alcohol: ',alcohol_consumptionDf.shape)\n",
    "\n",
    "alcohol_drug_consumptionDf = crashesDfNAClean[(crashesDfNAClean['alcohol']==1)&(crashesDfNAClean['drug']==1)]\n",
    "print('Alcohol Drug: ',alcohol_drug_consumptionDf.shape)\n",
    "\n",
    "unconsumedDf = crashesDfNAClean[(crashesDfNAClean['alcohol']==0)&(crashesDfNAClean['drug']==0)]\n",
    "print('Unconsumed: ',unconsumedDf.shape)\n",
    "\n",
    "print('Summation of categorized records',(drug_consumptionDf.shape[0] + alcohol_consumptionDf.shape[0]+ alcohol_drug_consumptionDf.shape[0]+unconsumedDf.shape[0]))\n",
    "print('CrashesDF records: ', crashesDfNAClean.shape[0])\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    drug_consumptionDfNew = pd.concat([drug_consumptionDf,alcohol_drug_consumptionDf],axis=0)\n",
    "    drug_consumptionDfNew['target'] = 'Drug'\n",
    "    alcohol_consumptionDf['target'] = 'Alcohol'\n",
    "    unconsumedDf['target']='Clean'\n",
    "\n",
    "crashesEditedDf = pd.concat([drug_consumptionDfNew, alcohol_consumptionDf, unconsumedDf], axis=0)\n",
    "crashesEditedDf['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ff694d1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['jurisdiction', 'number_of_lanes', 'fatal_count', 'young', 'deer',\n",
       "       'lighting', 'occupants', 'b_level_count', 'pedestrian', 'dis_ctrl_i',\n",
       "       'datetime', 'road_condition', 'number_of_units', 'school_bus',\n",
       "       'speed_limit', 'hour', 'hit_and_run', 'bicycle', 'motorcycle',\n",
       "       'a_level_count', 'c_level_count', 'most_severe_injury',\n",
       "       'red_light_running', 'weekday', 'intersecting_road',\n",
       "       'highway_classification', 'crash_type', 'train', 'weather',\n",
       "       'property_damage', 'lane_departure', 'primary_road', 'alcohol', 'drug',\n",
       "       'elderly', 'target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total Columns\n",
    "crashesEditedDf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "39b74462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the features which we don't want in the model\n",
    "crashesEditedDf=crashesEditedDf.drop(columns=['jurisdiction','deer','dis_ctrl_i','intersecting_road','primary_road','young',\n",
    "                                       'datetime','alcohol','drug','elderly','school_bus','train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2fe46a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning features to X and y\n",
    "X = crashesEditedDf.drop(columns=['target'])\n",
    "y = crashesEditedDf['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4bd1c3bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Drug       132109\n",
       "Alcohol    132109\n",
       "Clean      132109\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SMOTE Upsampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE()\n",
    "X_sm, y_sm = smote.fit_resample(X,y)\n",
    "\n",
    "y_sm.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d3231a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split\n",
    "X_train, X_test, y_train, y_test = create_splits(X_sm,y_sm,stratify=y_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c5bab6b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nishit Vyas\\anaconda3\\envs\\MLEnv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_score 65.39\n",
      "l2\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'clf__penalty': 'l2',\n",
    "             'clf__solver': 'lbfgs',\n",
    "             'clf__max_iter': 1000}\n",
    "mlflow_runLogR(model_params=param_grid,exp_name='TrafficCrash', run_Name='run4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2e409bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!mlflow ui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f1f07803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['jurisdiction', 'number_of_lanes', 'fatal_count', 'deer', 'lighting',\n",
       "       'occupants', 'b_level_count', 'pedestrian', 'dis_ctrl_i',\n",
       "       'road_condition', 'number_of_units', 'speed_limit', 'hour',\n",
       "       'hit_and_run', 'bicycle', 'motorcycle', 'a_level_count',\n",
       "       'c_level_count', 'most_severe_injury', 'red_light_running', 'weekday',\n",
       "       'highway_classification', 'crash_type', 'weather', 'property_damage',\n",
       "       'lane_departure', 'alcohol'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da9f6c9",
   "metadata": {},
   "source": [
    "## Deployment Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "91e9194b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "LRpipe = Pipeline([\n",
    "                    ('std', StandardScaler()),\n",
    "                    ('lr',LogisticRegression(C=1,penalty = 'l2', solver='lbfgs', max_iter=1000))\n",
    "])\n",
    "LRpipe.fit(X_train, y_train)\n",
    "pickle.dump(LRpipe,open('model1.pkl', 'wb') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "38629654",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open('model1.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3557d4fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Alcohol'], dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2389fd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_class(file):\n",
    "    df = pd.read_csv(file)\n",
    "    preds = loaded_model.predict(df)\n",
    "    df['target'] = preds\n",
    "    return(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "69753db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head(10).to_csv('./testFile.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd15f79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "37c65c38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bb3cdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
